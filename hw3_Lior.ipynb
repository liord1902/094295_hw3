{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from torch_geometric.data import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import degree\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW3Dataset(Dataset):\n",
    "    url = 'https://technionmail-my.sharepoint.com/:u:/g/personal/ploznik_campus_technion_ac_il/EUHUDSoVnitIrEA6ALsAK1QBpphP5jX3OmGyZAgnbUFo0A?download=1'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(HW3Dataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        file_url = self.url.replace(' ', '%20')\n",
    "        response = requests.get(file_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download the file, status code: {response.status_code}\")\n",
    "\n",
    "        with open(os.path.join(self.raw_dir, self.raw_file_names[0]), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    def process(self):\n",
    "        raw_path = os.path.join(self.raw_dir, self.raw_file_names[0])\n",
    "        data = torch.load(raw_path)\n",
    "        torch.save(data, self.processed_paths[0])\n",
    "\n",
    "    def len(self):\n",
    "        return 1\n",
    "\n",
    "    def get(self, idx):\n",
    "        return torch.load(self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bee19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HW3Dataset(root='data/hw3/')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da4dfb",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e6d41",
   "metadata": {},
   "source": [
    "#### Visualize sample of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(21)\n",
    "\n",
    "def convert_to_networkx(graph, n_sample=None):\n",
    "    g = to_networkx(graph, node_attrs=[\"x\"])\n",
    "    y = graph.y.numpy()\n",
    "\n",
    "    if n_sample is not None:\n",
    "        sampled_nodes = random.sample(g.nodes, n_sample)\n",
    "        g = g.subgraph(sampled_nodes)\n",
    "        y = y[sampled_nodes]\n",
    "\n",
    "    return g, y\n",
    "\n",
    "\n",
    "def plot_graph(g, y):\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    nx.draw_spring(g, node_size=30, arrows=False, node_color=y)\n",
    "    plt.savefig(\"Visualization\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "g, y = convert_to_networkx(data, n_sample=1000)\n",
    "plot_graph(g, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e62a9",
   "metadata": {},
   "source": [
    "#### Gather some statistics about the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fe6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "\n",
    "print(f'Number of training nodes: {data.train_mask.shape[0]}')\n",
    "print(f'Training node label rate: {int(data.train_mask.shape[0]) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930f716",
   "metadata": {},
   "source": [
    "#### node degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of degrees for each node\n",
    "degrees = degree(data.edge_index[0]).numpy()\n",
    "\n",
    "# Count the number of nodes for each degree\n",
    "numbers = Counter(degrees)\n",
    "\n",
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 7))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Number of nodes')\n",
    "ax.set_title('Nodes degree')\n",
    "ax.set_xlim(0, 50)\n",
    "plt.bar(numbers.keys(), numbers.values())\n",
    "plt.savefig(\"nodes_degree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Isolated nodes: {numbers[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b50783",
   "metadata": {},
   "source": [
    "#### node year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = data.node_year.squeeze().numpy()\n",
    "\n",
    "print(\"Minimum year:\", years.min())\n",
    "print(\"Maximum year:\", years.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41521cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(years, bins=len(np.unique(years)), edgecolor='black')\n",
    "plt.title(\"Node Years Distribution\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.savefig(\"Years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0affc",
   "metadata": {},
   "source": [
    "#### labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.y.squeeze().numpy()\n",
    "\n",
    "plt.hist(labels, bins=len(np.unique(labels)), density=True, edgecolor='black')\n",
    "plt.title(\"Labels Distribution\")\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"ratio\")\n",
    "plt.savefig(\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c045d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(years, labels)[0, 1]\n",
    "\n",
    "print(\"Correlation coefficient of years and labels: \", round(corr, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e7887",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d2a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.x\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train node year\n",
    "train_years = data.node_year[data.train_mask]\n",
    "min_year = torch.min(train_years)\n",
    "max_year = torch.max(train_years)\n",
    "normalized_train_years = (train_years - min_year) / (max_year - min_year)\n",
    "normalized_train_years = normalized_train_years.to(data.x.dtype)\n",
    "\n",
    "# Normalize val node year\n",
    "val_years = data.node_year[data.val_mask]\n",
    "min_year = torch.min(val_years)\n",
    "max_year = torch.max(val_years)\n",
    "normalized_val_years = (val_years - min_year) / (max_year - min_year)\n",
    "normalized_val_years = normalized_val_years.to(data.x.dtype)\n",
    "\n",
    "# Concatenate\n",
    "normalized_years = torch.cat((normalized_train_years, normalized_val_years), dim=0)\n",
    "features = torch.cat((features, normalized_years), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5587a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a9dc5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.edge_index\n",
    "train_mask = data.train_mask\n",
    "val_mask = data.val_mask\n",
    "y = data.y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "epochs = 500\n",
    "learning_rate = 0.005\n",
    "hidden_channels = 12\n",
    "num_heads = 15\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'  # CUDA out of memory\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439aff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dataset.num_features + 1, hidden_channels)\n",
    "        self.gcn2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ba765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.norm = torch.nn.BatchNorm1d(dataset.num_features + 1)\n",
    "        self.conv1 = GATConv(dataset.num_features + 1, hidden_channels, heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, dataset.num_classes, heads)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.norm(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT2Conv(torch.nn.Module):\n",
    "    def __init__(self, dim_h, heads):\n",
    "        super().__init__()\n",
    "        self.norm = torch.nn.BatchNorm1d(dataset.num_features + 1)\n",
    "        self.gat1 = GATv2Conv(dataset.num_features + 1, dim_h, heads)\n",
    "        self.gat2 = GATv2Conv(dim_h * heads, dataset.num_classes, heads)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.norm(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=dropout, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, optimizer, criterion):\n",
    "    \n",
    "    train_accuracies = []\n",
    "    train_losses = []\n",
    "    \n",
    "    val_accuracies = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs+1):\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(features, edge_index)\n",
    "        loss = criterion(out[train_mask], y[train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = out.argmax(dim=1)\n",
    "        acc = ((preds[train_mask] == y[train_mask]).sum() / len(y[train_mask])).item()\n",
    "        \n",
    "        train_accuracies.append(acc)\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = criterion(out[val_mask], y[val_mask])\n",
    "        val_acc = ((preds[val_mask] == y[val_mask]).sum() / len(y[val_mask])).item()\n",
    "        \n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss.item())\n",
    "        \n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: 'f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                  f'Val Acc: {val_acc*100:.2f}%')\n",
    "        \n",
    "    return train_accuracies, train_losses, val_accuracies, val_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b183e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GCN(hidden_channels)\n",
    "model = GAT(hidden_channels, num_heads)\n",
    "# model = GAT2Conv(hidden_channels, num_heads)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ab27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies, train_losses, val_accuracies, val_losses = train_and_eval(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3e17c",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), './model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb179fb",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a90d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GAT(hidden_channels, heads=num_heads)\n",
    "# model.load_state_dict(torch.load('./model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc0e5e",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Loss by epoch')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.savefig('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracies, label='Train')\n",
    "plt.plot(val_accuracies, label='Validation')\n",
    "plt.title('Accuracy by epoch')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.savefig('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d00b02",
   "metadata": {},
   "source": [
    "##  Model accuracy for each degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0779ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cpu')\n",
    "\n",
    "# Get model's classifications\n",
    "out = model(features, edge_index)\n",
    "\n",
    "# Calculate the degree of each node\n",
    "degrees = degree(edge_index[0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store accuracy scores and sample sizes\n",
    "accuracies = []\n",
    "sizes = []\n",
    "\n",
    "# Accuracy for degrees between 0 and 5\n",
    "for i in range(0, 6):\n",
    "    mask = np.where(degrees == i)[0]\n",
    "    y = data.y[mask].squeeze()\n",
    "    acc = ((out.argmax(dim=1)[mask] == y).sum() / len(y)).item()\n",
    "    accuracies.append(acc)\n",
    "    sizes.append(len(mask))\n",
    "    \n",
    "# Accuracy for degrees > 5\n",
    "mask = np.where(degrees > 5)[0]\n",
    "y = data.y[mask].squeeze()\n",
    "acc = ((out.argmax(dim=1)[mask] == y).sum() / len(y)).item()\n",
    "accuracies.append(acc)\n",
    "sizes.append(len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "fig, ax = plt.subplots(figsize=(18, 9))\n",
    "ax.set_xlabel('Node degree')\n",
    "ax.set_ylabel('Accuracy score')\n",
    "ax.set_title('Model accuracy for each degree')\n",
    "\n",
    "plt.bar(['0','1','2','3','4','5','>5'], accuracies, color='#0A047A')\n",
    "for i in range(0, 7):\n",
    "    plt.text(i, accuracies[i], f'{accuracies[i]*100:.2f}%', ha='center', color='#0A047A')\n",
    "for i in range(0, 7):\n",
    "    plt.text(i, accuracies[i]//2, sizes[i], ha='center', color='white')\n",
    "    \n",
    "# plt.savefig('accuracy_degree')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw3_env",
   "language": "python",
   "name": "hw3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
